{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UA8VcLZFk9pr"
   },
   "source": [
    "## Clasification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22m39mnbk9pv"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Importing Required Libraries\n",
    "\n",
    "The code block below will load all the datasets for classification problems.\n",
    "\n",
    "**Run the code cell below** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0Wvx7rTk9pw"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.svm               # For SVC\n",
    "import sklearn.model_selection   # For GridSearchCV and RandomizedSearchCV\n",
    "import scipy\n",
    "import scipy.stats               # For reciprocal distribution\n",
    "import warnings\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, recall_score, precision_score,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)       # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cy_ewTcDk9p2"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Loading All Datasets\n",
    "\n",
    "The code block below will load all the datasets for classification problems.\n",
    "\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Diabetic Retinopathy -> CP_1\n",
    "2. Default of credit card clients -> CP_2\n",
    "3. Breast Cancer Wisconsin -> CP_3\n",
    "4. Statlog (Australian credit approval) -> CP_4\n",
    "5. Statlog (German credit data) -> CP_5\n",
    "6. Steel Plates Faults -> CP_6\n",
    "7. Adult -> CP_7\n",
    "8. Yeast -> CP_8\n",
    "9. Thoracic Surgery Data -> CP_9\n",
    "10. Seismic-Bumps -> CP_10\n",
    "\n",
    "**Run the code cell below to load the data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXU178Vmk9p3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "\"\"\"\n",
    "Splits the data into Features (X) and Labels (y)\n",
    "\"\"\"\n",
    "def splitData(data):\n",
    "    X = data.iloc[:,:len(data.columns)-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    #print(y.value_counts())\n",
    "    return X,y\n",
    "\n",
    "\"\"\"\n",
    "Splits data into Training Set and Testing Set. \n",
    "Size Ratio of Train:Test is 80:20 \n",
    "\"\"\"\n",
    "def getTrainTestData(data):\n",
    "    X,y = splitData(data)\n",
    "    #if type(y[0]) is int:\n",
    "    y = y.astype(int)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Converts categorical features by encoding\n",
    "\"\"\"\n",
    "def convertCategorical(df):\n",
    "    categorical_feature_mask = df.dtypes==object\n",
    "    categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "    le = LabelEncoder()\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "    return df;\n",
    "\n",
    "\"\"\"\n",
    "Checks for ? in the data frame\n",
    "\"\"\"\n",
    "def check(df):\n",
    "    dic = {}\n",
    "    lst = df.columns[df.isin([' ?']).any()]\n",
    "    for x in lst:\n",
    "        dic = df[x].value_counts().to_dict()\n",
    "        key_list = list(dic.keys()) \n",
    "        val_list = list(dic.values())\n",
    "        maxi=key_list[val_list.index(max(val_list))]\n",
    "        df[x]=df[x].replace(' ?', maxi)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns min and max value of every column\n",
    "\"\"\"\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "colab_type": "code",
    "id": "CeXxdcr-k9p7",
    "outputId": "22c5dd3a-11d4-42ce-bdf0-ecd245d1de07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance count for diabetic retinopathy data set\n",
      "b'1'    611\n",
      "b'0'    540\n",
      "Name: Class, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for default credit card clients data set\n",
      "0    23364\n",
      "1     6636\n",
      "Name: 23, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for breast cancer data set\n",
      "0    458\n",
      "1    241\n",
      "Name: 10, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for australian credit approval data set\n",
      "0    383\n",
      "1    307\n",
      "Name: 14, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for german credit data set\n",
      "1    700\n",
      "2    300\n",
      "Name: 24, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for steel plates faults data set\n",
      "0    1268\n",
      "1     673\n",
      "Name: 33, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for adult data set\n",
      "0    24720\n",
      "1     7841\n",
      "Name: 14, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for yeast data set\n",
      "0    463\n",
      "7    429\n",
      "6    244\n",
      "5    163\n",
      "4     51\n",
      "3     44\n",
      "2     35\n",
      "9     30\n",
      "8     20\n",
      "1      5\n",
      "Name: 9, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for thoracic surgery data set\n",
      "0    400\n",
      "1     70\n",
      "Name: 16, dtype: int64\n",
      "\n",
      "------------------------------------------------------------\n",
      "Class balance count for seismic bumps data set\n",
      "0    2414\n",
      "1     170\n",
      "Name: 15, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Classification Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Diabetic Retinopathy Data | 19 Features | 1151 Samples\n",
    "CP_1 = arff.loadarff('CP_Data/messidor_features.arff')\n",
    "CP_1 = pd.DataFrame(CP_1[0])\n",
    "print('Class balance count for diabetic retinopathy data set')\n",
    "print(CP_1.iloc[:,-1].value_counts())\n",
    "CP_1_X_train, CP_1_X_test, CP_1_y_train, CP_1_y_test = getTrainTestData(CP_1)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Default of Credit Card Clients Data| 23 Features | 30000 Samples\n",
    "CP_2 = pd.read_excel ('CP_Data/credit.xls',header=None,skiprows=2)\n",
    "CP_2 = CP_2.drop(0, 1)\n",
    "CP_2.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "print('Class balance count for default credit card clients data set')\n",
    "print(CP_2.iloc[:,-1].value_counts())\n",
    "CP_2_X_train, CP_2_X_test, CP_2_y_train, CP_2_y_test = getTrainTestData(CP_2)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Breast Cancer Wisconsin Data | 10 Features | 699 Samples\n",
    "CP_3 = pd.read_csv(\"CP_Data/breast-cancer-wisconsin.data\", sep=\",\",header=None)\n",
    "CP_3=CP_3.replace('?', 5.5)\n",
    "#print(CP_3cp[6].value_counts())\n",
    "CP_3[6]=CP_3[6].astype(int)\n",
    "CP_3[10]= CP_3[10].replace(2,0)\n",
    "CP_3[10]= CP_3[10].replace(4,1)\n",
    "print('Class balance count for breast cancer data set')\n",
    "print(CP_3.iloc[:,-1].value_counts())\n",
    "CP_3_X_train, CP_3_X_test, CP_3_y_train, CP_3_y_test = getTrainTestData(CP_3)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Australian Credit Approval Data | 14 Features | 690 Samples\n",
    "CP_4 = pd.read_csv(\"CP_Data/australian.dat\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for australian credit approval data set')\n",
    "print(CP_4.iloc[:,-1].value_counts())\n",
    "CP_4_X_train, CP_4_X_test, CP_4_y_train, CP_4_y_test = getTrainTestData(CP_4)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# German Credit Data | 24 Features | 1000 Samples\n",
    "CP_5 = pd.read_csv(\"CP_Data/german.data-numeric\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for german credit data set')\n",
    "print(CP_5.iloc[:,-1].value_counts())\n",
    "CP_5_X_train, CP_5_X_test, CP_5_y_train, CP_5_y_test = getTrainTestData(CP_5)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Steel Plates Faults Data | 33 Features | 1941 Samples\n",
    "CP_6 = pd.read_csv(\"CP_Data/Faults.NNA\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for steel plates faults data set')\n",
    "print(CP_6.iloc[:,-1].value_counts())\n",
    "CP_6_X_train, CP_6_X_test, CP_6_y_train, CP_6_y_test = getTrainTestData(CP_6)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "#Adult Data | 14 Features | 49382 Samples\n",
    "CP_7 = pd.read_csv(\"CP_Data/adult.data\", sep=\",\",header=None)\n",
    "if(' ?' in CP_7.values):\n",
    "    CP_7=check(CP_7)\n",
    "CP_7= convertCategorical(CP_7)\n",
    "print('Class balance count for adult data set')\n",
    "print(CP_7.iloc[:,-1].value_counts())\n",
    "CP_7_X_train, CP_7_y_train = splitData(CP_7)\n",
    "CP_7_test = pd.read_csv(\"CP_Data/adult.test\", sep=\",\",header=None,skiprows=1)\n",
    "if(' ?' in CP_7_test.values):\n",
    "    CP_7_test=check(CP_7_test)\n",
    "CP_7_test= convertCategorical(CP_7_test)\n",
    "CP_7_X_test, CP_7_y_test = splitData(CP_7_test)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Yeast Data | 9 Features | 1484 Samples\n",
    "CP_8 = pd.read_csv(\"CP_Data/yeast.data\", sep=\"\\s+\",header=None)\n",
    "CP_8= convertCategorical(CP_8)\n",
    "X1,y1 = splitData(CP_8)\n",
    "print('Class balance count for yeast data set')\n",
    "print(CP_8.iloc[:,-1].value_counts())\n",
    "CP_8_X_train, CP_8_X_test, CP_8_y_train, CP_8_y_test = sklearn.model_selection.train_test_split(X1,y1,test_size=0.2,random_state=0)\n",
    "#CP_8_X_train, CP_8_X_test, CP_8_y_train, CP_8_y_test = getTrainTestData(CP_8)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Thoracic Surgery Data | 16 Features | 470 Samples\n",
    "CP_9 = arff.loadarff('CP_Data/ThoraricSurgery.arff')\n",
    "CP_9 = pd.DataFrame(CP_9[0])\n",
    "CP_9.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "CP_9= convertCategorical(CP_9)\n",
    "print('Class balance count for thoracic surgery data set')\n",
    "print(CP_9.iloc[:,-1].value_counts())\n",
    "CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = getTrainTestData(CP_9)\n",
    "print()\n",
    "#X2,y2 = splitData(CP_9)\n",
    "#CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = sklearn.model_selection.train_test_split(X2,y2,test_size=0.2,random_state=0)\n",
    "#CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = getTrainTestData(CP_9)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Seismic-Bumps | 18 Features | 2584 Samples\n",
    "# delete column 13 14 15 bcs of one same value\n",
    "CP_10 = arff.loadarff('CP_Data/seismic-bumps.arff')\n",
    "CP_10 = pd.DataFrame(CP_10[0])\n",
    "#plt.matshow(CP_101.corr())\n",
    "#plt.show()\n",
    "CP_10.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "del CP_10[13]\n",
    "del CP_10[14]\n",
    "del CP_10[15]\n",
    "CP_10.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "CP_10= convertCategorical(CP_10)\n",
    "print('Class balance count for seismic bumps data set')\n",
    "print(CP_10.iloc[:,-1].value_counts())\n",
    "CP_10_X_train, CP_10_X_test, CP_10_y_train, CP_10_y_test = getTrainTestData(CP_10)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print('Classification Data Loaded Successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 3. Classifiers and Hyper Parameter Search Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0cVY679k9p-"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## Hyper Parameter Search Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJZkvBtYk9p-"
   },
   "source": [
    "#### Logistic Regression Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQ3-YoyQk9p_"
   },
   "outputs": [],
   "source": [
    "def randomSearchLRC(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'C'     : scipy.stats.reciprocal(0.01, 1000.),\n",
    "        'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5, n_iter=50,n_jobs=4,  random_state=23).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDwfo3n6k9qC"
   },
   "outputs": [],
   "source": [
    "def gridSearchLRC(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = { \n",
    "        'C' : np.logspace(-2, 3, 10),\n",
    "        'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    }\n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_grid,n_jobs=4,   cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ntMN0S9k9qE"
   },
   "source": [
    "#### Decision Tree Parameter Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ftD575Qk9qF"
   },
   "outputs": [],
   "source": [
    "def randomSearchDTC(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_grid, n_jobs=4, cv=5, n_iter=50,random_state=0).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LPAS5kwk9qI"
   },
   "outputs": [],
   "source": [
    "def gridSearchDTC(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_grid, n_jobs=4,  cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1EARzDZk9qK"
   },
   "source": [
    "#### K-Nearest Neighbours Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhGK6q99k9qL"
   },
   "outputs": [],
   "source": [
    "def randomSearchKNN(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'n_neighbors'     : [3,5,11,19],\n",
    "        'weights' : ['uniform', 'distance'],\n",
    "        'p' : [1,2],\n",
    "        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5,n_jobs=4,  n_iter=50,  random_state=0).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOOTn4Pnk9qN"
   },
   "outputs": [],
   "source": [
    "def gridSearchKNN(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = { \n",
    "        'n_neighbors' : [3,5,11,19], \n",
    "        'weights' : ['uniform', 'distance'], \n",
    "        'p': [1,2], \n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_grid,n_jobs=4,   cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tz-jQejEk9qT"
   },
   "source": [
    "#### Random Forest Parameter Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQa5dDA1k9qV"
   },
   "outputs": [],
   "source": [
    "def randomSearchRFC(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_grid = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10,20,50,100,150,200,250]\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_grid, cv=5,n_jobs=4,  n_iter=50, random_state=0).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCG4YUQqk9qY"
   },
   "outputs": [],
   "source": [
    "def gridSearchRFC(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10,20,50,100,150,200,250]\n",
    "    }   \n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_grid,n_jobs=4,   cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g47WuA-Lk9qb"
   },
   "source": [
    "#### AdaBoost Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyLRrvxKk9qb"
   },
   "outputs": [],
   "source": [
    "def randomSearchABC(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_dist,n_jobs=4,  n_iter=50, random_state=0).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGvI8P2qk9qe"
   },
   "outputs": [],
   "source": [
    "def gridSearchABC(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate' : [0.01,0.05,0.1,0.3,1],\n",
    "    }\n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_dist,n_jobs=4,  cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network classification Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSearchNNC(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    \n",
    "    x1 = range(3)\n",
    "    param_dist = {        \n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'batch_size': np.power(2, x1),\n",
    "    'momentum': [0.3,0.4,0.6,0.7,0.9],\n",
    "    }\n",
    "    \n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_dist,n_jobs=4,  n_iter=50, random_state=0)\n",
    "    randcv.fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (randcv.best_score_*100))\n",
    "    return randcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchNNC(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_dist = {        \n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'batch_size': [ 1, 2, 4],\n",
    "    'momentum': [0.3,0.4,0.6,0.7,0.9],\n",
    "    }\n",
    "    \n",
    "    gridcv = sklearn.model_selection.GridSearchCV(model, param_dist,n_jobs=4,  cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    print(\"%.1f%% accuracy on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSearchSVM(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'C'     : scipy.stats.reciprocal(1.0, 1000.),\n",
    "        'gamma' : scipy.stats.reciprocal(0.01, 10.),\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5,n_jobs=4, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchSVM(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma' : [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    gridcv =  sklearn.model_selection.GridSearchCV(model, param_grid,n_jobs=4, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nebwUyJFk9qi"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## Score Helper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ktS5HZlk9qj"
   },
   "outputs": [],
   "source": [
    "def scoreHelper(clf, X_train, X_test, y_train, y_test, parity):\n",
    "    print('Training Accuracy : ',clf.score(X_train,y_train))\n",
    "    print('Testing Accuracy : ',clf.score(X_test,y_test))\n",
    "    if parity == '1' or parity == '2' or parity == '3' or parity == '5':\n",
    "        print('Training Recall score : ',recall_score(y_train,clf.predict(X_train)))\n",
    "        print(\"Testing Recall score : \", recall_score(y_test,clf.predict(X_test)))\n",
    "    elif parity == '4':\n",
    "        print('Training Precision score : ',precision_score(y_train,clf.predict(X_train)))\n",
    "        print(\"Testing Precision score : \", precision_score(y_test,clf.predict(X_test)))\n",
    "    else:\n",
    "        print(\"Training f1 score : \", f1_score(y_train,clf.predict(X_train),average=None))\n",
    "        print(\"Testing f1 score : \", f1_score(y_test,clf.predict(X_test),average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1n_hBE3_k9qo"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvBrlZ0ak9qp"
   },
   "source": [
    "#### Logistic Regression (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mp7vK2L1k9qp"
   },
   "outputs": [],
   "source": [
    "def LRC(X_train, X_test, y_train, y_test, parity, hs, C=1, solver='newton-cg'):\n",
    "    print('\\nResult for Logistic Regression Classification')\n",
    "    clf = LogisticRegression(C=C, solver=solver)    \n",
    "    if hs:\n",
    "        clf = gridSearchLRC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchLRC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGP118TVk9qs"
   },
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Zyw0nC1k9qt"
   },
   "outputs": [],
   "source": [
    "def NBC(X_train, X_test, y_train, y_test, parity, hs):\n",
    "    print('\\nResult for Gaussian Naive Bayes Classification')\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ye2OXIbMk9qv"
   },
   "source": [
    "####  K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g66mu2I9k9qx"
   },
   "outputs": [],
   "source": [
    "def KNN(X_train, X_test, y_train, y_test, parity, hs, n_neighbors=5, weights='uniform', p=2, algorithm='auto'):\n",
    "    print('\\nResult for K-Nearest Neighbours Classification')\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, algorithm=algorithm)\n",
    "    if hs:\n",
    "        clf = gridSearchKNN(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchKNN(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEk0Uo-Wk9q5"
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFZhsjO5k9q7"
   },
   "outputs": [],
   "source": [
    "def SVM(X_train, X_test, y_train, y_test, parity, hs, C=1, gamma='scale'):\n",
    "    print('\\nResult for SVM Classification')\n",
    "    clf = SVC(C=1, gamma='scale')\n",
    "    if hs:\n",
    "        clf = gridSearchSVM(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchSVM(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2VAKotHk9q-"
   },
   "source": [
    "#### Decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocEtnoB7k9q_"
   },
   "outputs": [],
   "source": [
    "def  DTC(X_train, X_test, y_train, y_test, parity, hs, max_depth=None, max_features=None,min_samples_leaf=1,min_samples_split=2):\n",
    "    print('\\nResult for Decision Tree Classification')\n",
    "    clf = tree.DecisionTreeClassifier(random_state = 0, max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split)\n",
    "    if hs:\n",
    "        clf = gridSearchDTC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchDTC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thgyosxUk9rC"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzuAXKjSk9rE"
   },
   "outputs": [],
   "source": [
    "def RFC(X_train, X_test, y_train, y_test, parity, hs, max_depth=None, max_features='auto',min_samples_leaf=1,min_samples_split=2, bootstrap=True,n_estimators=100):\n",
    "    print('\\nResult for Random Forest Classification')\n",
    "    clf = RandomForestClassifier(max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split, bootstrap=bootstrap, n_estimators=n_estimators, random_state=0)\n",
    "    if hs:\n",
    "        clf = gridSearchRFC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchRFC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmPHHjAGk9rN"
   },
   "source": [
    "#### AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLdI7ZCWk9rQ"
   },
   "outputs": [],
   "source": [
    "def ABC(X_train, X_test, y_train, y_test, parity, hs, n_estimators=50, learning_rate=1):\n",
    "    print('\\nResult for AdaBoost Classification')\n",
    "    clf = AdaBoostClassifier(n_estimators=n_estimators,learning_rate=learning_rate,random_state=0)\n",
    "    if hs:\n",
    "        clf = gridSearchABC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchABC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrHE37KOk9rS"
   },
   "source": [
    "#### Neural Network (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXZB8kMQk9rT"
   },
   "outputs": [],
   "source": [
    "def NNC(X_train, X_test, y_train, y_test, parity, hs,  activation='relu', solver='adam', learning_rate='constant',batch_size='auto', momentum=0.0):\n",
    "    print('\\nResult for Neural Network Classification')\n",
    "    clf = MLPClassifier(activation=activation, solver=solver, learning_rate=learning_rate,batch_size=batch_size, momentum=momentum)\n",
    "    if hs:\n",
    "        clf = gridSearchNNC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "        clf = randomSearchNNC(clf,X_train,y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scoreHelper(clf, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrEIucSbk9rV"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 4. Working with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53taUDmRk9rW"
   },
   "outputs": [],
   "source": [
    "def classification(X_train, X_test, y_train, y_test, parity, hs = False):\n",
    "    LRC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    NBC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    DTC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    RFC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    KNN(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    ABC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    NNC(X_train, X_test, y_train, y_test, parity, hs)\n",
    "    SVM(X_train, X_test, y_train, y_test, parity, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "colab_type": "code",
    "id": "woq4h1jyk9rY",
    "outputId": "df2b769f-a0f1-446f-80a4-b8ccf73f1087",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetic Retinopathy Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.7630434782608696\n",
      "Testing Accuracy :  0.7359307359307359\n",
      "Training Recall score :  0.7006237006237006\n",
      "Testing Recall score :  0.676923076923077\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.6054347826086957\n",
      "Testing Accuracy :  0.5367965367965368\n",
      "Training Recall score :  0.3076923076923077\n",
      "Testing Recall score :  0.23846153846153847\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.5887445887445888\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.6076923076923076\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.6623376623376623\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.6307692307692307\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.7804347826086957\n",
      "Testing Accuracy :  0.6190476190476191\n",
      "Training Recall score :  0.735966735966736\n",
      "Testing Recall score :  0.6230769230769231\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.783695652173913\n",
      "Testing Accuracy :  0.6493506493506493\n",
      "Training Recall score :  0.7588357588357588\n",
      "Testing Recall score :  0.6076923076923076\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.7782608695652173\n",
      "Testing Accuracy :  0.7316017316017316\n",
      "Training Recall score :  0.7484407484407485\n",
      "Testing Recall score :  0.7307692307692307\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.7119565217391305\n",
      "Testing Accuracy :  0.658008658008658\n",
      "Training Recall score :  0.5571725571725572\n",
      "Testing Recall score :  0.5384615384615384\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Default of Credit Card Clients Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.806875\n",
      "Testing Accuracy :  0.8176666666666667\n",
      "Training Recall score :  0.23262783292751452\n",
      "Testing Recall score :  0.23438704703161142\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.372\n",
      "Testing Accuracy :  0.36466666666666664\n",
      "Training Recall score :  0.8943622401198726\n",
      "Testing Recall score :  0.899768696993061\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  0.999625\n",
      "Testing Accuracy :  0.7376666666666667\n",
      "Training Recall score :  0.9985015920584379\n",
      "Testing Recall score :  0.42945258288357746\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  0.9995833333333334\n",
      "Testing Accuracy :  0.8216666666666667\n",
      "Training Recall score :  0.9988761940438284\n",
      "Testing Recall score :  0.38396299151888974\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.8159166666666666\n",
      "Testing Accuracy :  0.7623333333333333\n",
      "Training Recall score :  0.33657988387338456\n",
      "Testing Recall score :  0.19506553585196607\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.8152916666666666\n",
      "Testing Accuracy :  0.826\n",
      "Training Recall score :  0.3152275707061247\n",
      "Testing Recall score :  0.3269082498072475\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.7069583333333334\n",
      "Testing Accuracy :  0.7111666666666666\n",
      "Training Recall score :  0.2845102079041019\n",
      "Testing Recall score :  0.28758673862760215\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.7776666666666666\n",
      "Testing Accuracy :  0.7838333333333334\n",
      "Training Recall score :  0.0005619029780857839\n",
      "Testing Recall score :  0.0\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Breast Cancer Wisconsin Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.9695885509838998\n",
      "Testing Accuracy :  0.9714285714285714\n",
      "Training Recall score :  0.956989247311828\n",
      "Testing Recall score :  0.9818181818181818\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.7996422182468694\n",
      "Testing Accuracy :  0.7428571428571429\n",
      "Training Recall score :  0.3978494623655914\n",
      "Testing Recall score :  0.36363636363636365\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.9357142857142857\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.8909090909090909\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.9785714285714285\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.9818181818181818\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.7620751341681574\n",
      "Testing Accuracy :  0.6\n",
      "Training Recall score :  0.46774193548387094\n",
      "Testing Recall score :  0.34545454545454546\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.998211091234347\n",
      "Testing Accuracy :  0.9428571428571428\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.9090909090909091\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.669051878354204\n",
      "Testing Accuracy :  0.6142857142857143\n",
      "Training Recall score :  0.005376344086021506\n",
      "Testing Recall score :  0.01818181818181818\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.667262969588551\n",
      "Testing Accuracy :  0.6071428571428571\n",
      "Training Recall score :  0.0\n",
      "Testing Recall score :  0.0\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Australian Credit Approval Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.8786231884057971\n",
      "Testing Accuracy :  0.8913043478260869\n",
      "Training Precision score :  0.854251012145749\n",
      "Testing Precision score :  0.9032258064516129\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.7844202898550725\n",
      "Testing Accuracy :  0.8043478260869565\n",
      "Training Precision score :  0.847457627118644\n",
      "Testing Precision score :  0.9523809523809523\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.8043478260869565\n",
      "Training Precision score :  1.0\n",
      "Testing Precision score :  0.796875\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.8913043478260869\n",
      "Training Precision score :  1.0\n",
      "Testing Precision score :  0.890625\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.7771739130434783\n",
      "Testing Accuracy :  0.717391304347826\n",
      "Training Precision score :  0.784688995215311\n",
      "Testing Precision score :  0.75\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.9057971014492754\n",
      "Testing Accuracy :  0.855072463768116\n",
      "Training Precision score :  0.889344262295082\n",
      "Testing Precision score :  0.8813559322033898\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.7952898550724637\n",
      "Testing Accuracy :  0.7536231884057971\n",
      "Training Precision score :  0.7529411764705882\n",
      "Testing Precision score :  0.7384615384615385\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.657608695652174\n",
      "Testing Accuracy :  0.6231884057971014\n",
      "Training Precision score :  0.797752808988764\n",
      "Testing Precision score :  0.76\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "German Credit Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.7875\n",
      "Testing Accuracy :  0.765\n",
      "Training Recall score :  0.9068100358422939\n",
      "Testing Recall score :  0.8380281690140845\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.7375\n",
      "Testing Accuracy :  0.71\n",
      "Training Recall score :  0.7777777777777778\n",
      "Testing Recall score :  0.7464788732394366\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.67\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.7323943661971831\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.735\n",
      "Training Recall score :  1.0\n",
      "Testing Recall score :  0.8732394366197183\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.79125\n",
      "Testing Accuracy :  0.695\n",
      "Training Recall score :  0.910394265232975\n",
      "Testing Recall score :  0.8309859154929577\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.8125\n",
      "Testing Accuracy :  0.77\n",
      "Training Recall score :  0.9032258064516129\n",
      "Testing Recall score :  0.8450704225352113\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.84\n",
      "Testing Accuracy :  0.76\n",
      "Training Recall score :  0.9175627240143369\n",
      "Testing Recall score :  0.8309859154929577\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.71375\n",
      "Testing Accuracy :  0.715\n",
      "Training Recall score :  0.9910394265232975\n",
      "Testing Recall score :  0.9788732394366197\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Steel Plates Faults Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.9188144329896907\n",
      "Testing Accuracy :  0.9357326478149101\n",
      "Training f1 score :  [0.93936477 0.87719298]\n",
      "Testing f1 score :  [0.95344507 0.89626556]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.5038659793814433\n",
      "Testing Accuracy :  0.46786632390745503\n",
      "Training f1 score :  [0.3984375  0.57785088]\n",
      "Testing f1 score :  [0.37837838 0.53483146]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  1.0\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [1. 1.]\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  1.0\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [1. 1.]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.759020618556701\n",
      "Testing Accuracy :  0.6606683804627249\n",
      "Training f1 score :  [0.82291667 0.62298387]\n",
      "Testing f1 score :  [0.7509434  0.46774194]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  1.0\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [1. 1.]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.6527061855670103\n",
      "Testing Accuracy :  0.6298200514138818\n",
      "Training f1 score :  [0.72344792 0.53333333]\n",
      "Testing f1 score :  [0.71428571 0.47445255]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.654639175257732\n",
      "Testing Accuracy :  0.6683804627249358\n",
      "Training f1 score :  [0.78930818 0.04285714]\n",
      "Testing f1 score :  [0.8        0.03007519]\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Adult Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.8247596818279537\n",
      "Testing Accuracy :  0.8264234383637369\n",
      "Training f1 score :  [0.89114426 0.55085013]\n",
      "Testing f1 score :  [0.89253936 0.54885057]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.7952765578452751\n",
      "Testing Accuracy :  0.795098581168233\n",
      "Training f1 score :  [0.87557862 0.4226572 ]\n",
      "Testing f1 score :  [0.87587439 0.41329581]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  0.9999692884125181\n",
      "Testing Accuracy :  0.8086112646643326\n",
      "Training f1 score :  [0.99997977 0.99993623]\n",
      "Testing f1 score :  [0.8740603  0.60153453]\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  0.9999692884125181\n",
      "Testing Accuracy :  0.8545543885510718\n",
      "Training f1 score :  [0.99997977 0.99993623]\n",
      "Testing f1 score :  [0.90727543 0.66287016]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.8366143545959891\n",
      "Testing Accuracy :  0.7758122965419815\n",
      "Training f1 score :  [0.89858554 0.57991156]\n",
      "Testing f1 score :  [0.86199335 0.40300949]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.8604465464819877\n",
      "Testing Accuracy :  0.8599594619495117\n",
      "Training f1 score :  [0.91128812 0.67309353]\n",
      "Testing f1 score :  [0.91144255 0.66549296]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.7910690703602469\n",
      "Testing Accuracy :  0.7872980775136662\n",
      "Training f1 score :  [0.87056451 0.45848921]\n",
      "Testing f1 score :  [0.86821174 0.44900557]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.796750714044409\n",
      "Testing Accuracy :  0.7990295436398256\n",
      "Training f1 score :  [0.88175386 0.27703736]\n",
      "Testing f1 score :  [0.88355043 0.26702509]\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Yeast Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.5636057287278854\n",
      "Testing Accuracy :  0.5622895622895623\n",
      "Training f1 score :  [0.59243697 0.         0.         0.62962963 0.17021277 0.73809524\n",
      " 0.54731458 0.53445378 0.58333333 0.        ]\n",
      "Testing f1 score :  [0.60240964 0.         0.42105263 0.         0.69387755 0.57142857\n",
      " 0.53947368 0.66666667 0.        ]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.5754001684919966\n",
      "Testing Accuracy :  0.5757575757575758\n",
      "Training f1 score :  [0.59004739 0.58823529 0.55263158 0.63333333 0.45454545 0.77697842\n",
      " 0.61077844 0.5026362  0.64285714 0.06896552]\n",
      "Testing f1 score :  [0.62443439 0.         0.47619048 0.66666667 0.2962963  0.70588235\n",
      " 0.62790698 0.53521127 0.57142857 0.        ]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.5252525252525253\n",
      "Training f1 score :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Testing f1 score :  [0.54255319 0.375      0.47619048 0.28571429 0.76923077 0.52336449\n",
      " 0.53571429 0.18181818 0.        ]\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.622895622895623\n",
      "Training f1 score :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Testing f1 score :  [0.60576923 0.30769231 0.75       0.35294118 0.75862069 0.63736264\n",
      " 0.63953488 0.66666667 0.        ]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.6764953664700927\n",
      "Testing Accuracy :  0.5488215488215489\n",
      "Training f1 score :  [0.74385965 0.33333333 0.56       0.23809524 0.35135135 0.55938697\n",
      " 0.71060172 0.71491876 0.18181818 0.57894737]\n",
      "Testing f1 score :  [0.625      0.2        0.         0.42857143 0.31578947 0.61702128\n",
      " 0.58139535 0.         0.33333333]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.45324347093513057\n",
      "Testing Accuracy :  0.43097643097643096\n",
      "Training f1 score :  [0.57267189 0.88888889 0.55384615 0.56666667 0.37837838 0.75496689\n",
      " 0.06722689 0.11650485 0.57142857 0.10810811]\n",
      "Testing f1 score :  [0.57239057 0.28571429 0.66666667 0.2        0.68852459 0.15873016\n",
      " 0.0776699  0.57142857 0.        ]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.3091828138163437\n",
      "Testing Accuracy :  0.3164983164983165\n",
      "Training f1 score :  [0.13362069 0.         0.         0.         0.         0.\n",
      " 0.04975124 0.46521434 0.         0.        ]\n",
      "Testing f1 score :  [0.15384615 0.         0.         0.         0.         0.07692308\n",
      " 0.46857143 0.         0.        ]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.3184498736310025\n",
      "Testing Accuracy :  0.32996632996632996\n",
      "Training f1 score :  [0.36915888 0.         0.         0.         0.         0.\n",
      " 0.         0.4238921  0.         0.        ]\n",
      "Testing f1 score :  [0.34259259 0.         0.         0.         0.         0.\n",
      " 0.45864662 0.         0.        ]\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Thoracic Surgery Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.8617021276595744\n",
      "Testing Accuracy :  0.8085106382978723\n",
      "Training f1 score :  [0.92550143 0.03703704]\n",
      "Testing f1 score :  [0.89411765 0.        ]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.18882978723404256\n",
      "Testing Accuracy :  0.20212765957446807\n",
      "Training f1 score :  [0.11078717 0.25427873]\n",
      "Testing f1 score :  [0.05063291 0.31192661]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.6808510638297872\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.80519481 0.11764706]\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.8085106382978723\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.89411765 0.        ]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.8670212765957447\n",
      "Testing Accuracy :  0.8085106382978723\n",
      "Training f1 score :  [0.92816092 0.10714286]\n",
      "Testing f1 score :  [0.89411765 0.        ]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.8803191489361702\n",
      "Testing Accuracy :  0.7978723404255319\n",
      "Training f1 score :  [0.9341142  0.34782609]\n",
      "Testing f1 score :  [0.88757396 0.        ]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.8617021276595744\n",
      "Testing Accuracy :  0.8085106382978723\n",
      "Training f1 score :  [0.92571429 0.        ]\n",
      "Testing f1 score :  [0.89411765 0.        ]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.8617021276595744\n",
      "Testing Accuracy :  0.8085106382978723\n",
      "Training f1 score :  [0.92571429 0.        ]\n",
      "Testing f1 score :  [0.89411765 0.        ]\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "Seismic-Bumps Dataset\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.9298500241896468\n",
      "Testing Accuracy :  0.941972920696325\n",
      "Training f1 score :  [0.96359528 0.0397351 ]\n",
      "Testing f1 score :  [0.97011952 0.        ]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.9032414126753749\n",
      "Testing Accuracy :  0.9052224371373307\n",
      "Training f1 score :  [0.94842702 0.21875   ]\n",
      "Testing f1 score :  [0.94984647 0.14035088]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.8858800773694391\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.93847758 0.21333333]\n",
      "\n",
      "Result for Random Forest Classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.9400386847195358\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.96903097 0.06060606]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.9332365747460087\n",
      "Testing Accuracy :  0.9381044487427466\n",
      "Training f1 score :  [0.96518668 0.18823529]\n",
      "Testing f1 score :  [0.968      0.05882353]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.9366231253023706\n",
      "Testing Accuracy :  0.9342359767891683\n",
      "Training f1 score :  [0.96699421 0.20606061]\n",
      "Testing f1 score :  [0.966 0.   ]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.9308176100628931\n",
      "Testing Accuracy :  0.9439071566731141\n",
      "Training f1 score :  [0.96416938 0.        ]\n",
      "Testing f1 score :  [0.97114428 0.        ]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.9308176100628931\n",
      "Testing Accuracy :  0.9477756286266924\n",
      "Training f1 score :  [0.96416938 0.        ]\n",
      "Testing f1 score :  [0.97318769 0.        ]\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Diabetic Retinopathy Dataset')\n",
    "classification(CP_1_X_train, CP_1_X_test, CP_1_y_train, CP_1_y_test,'1',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nDefault of Credit Card Clients Dataset')\n",
    "classification(CP_2_X_train, CP_2_X_test, CP_2_y_train, CP_2_y_test,'2',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nBreast Cancer Wisconsin Dataset')\n",
    "classification(CP_3_X_train, CP_3_X_test, CP_3_y_train, CP_3_y_test,'3',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nAustralian Credit Approval Dataset')\n",
    "classification(CP_4_X_train, CP_4_X_test, CP_4_y_train, CP_4_y_test, '4',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nGerman Credit Dataset')\n",
    "classification(CP_5_X_train, CP_5_X_test, CP_5_y_train, CP_5_y_test,'5',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nSteel Plates Faults Dataset')\n",
    "classification(CP_6_X_train, CP_6_X_test, CP_6_y_train, CP_6_y_test,'6',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nAdult Dataset')\n",
    "classification(CP_7_X_train, CP_7_X_test, CP_7_y_train, CP_7_y_test,'7',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nYeast Dataset')\n",
    "classification(CP_8_X_train, CP_8_X_test, CP_8_y_train, CP_8_y_test,'8',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nThoracic Surgery Dataset')\n",
    "classification(CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test,'9',hs = False)\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "print('\\n\\nSeismic-Bumps Dataset')\n",
    "classification(CP_10_X_train, CP_10_X_test, CP_10_y_train, CP_10_y_test,'10',hs = False)\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty 1. Heart Disease Classification\n",
    "\n",
    "### Feature Information\n",
    "\n",
    "1. age - in years\n",
    "2. sex - (1 = male; 0 = female)\n",
    "3. cp - chest pain type\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol - serum cholestoral in mg/dl\n",
    "6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "7. restecg - resting electrocardiographic results\n",
    "8. thalach - maximum heart rate achieved\n",
    "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak - ST depression induced by exercise relative to rest\n",
    "11. slope - the slope of the peak exercise ST segment\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy\n",
    "13. thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. target - 1 = heart disease or 0 = no heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novelty1. Heart Disease Classification\n",
      "\n",
      "Result for Logistic Regression Classification\n",
      "Training Accuracy :  0.8388429752066116\n",
      "Testing Accuracy :  0.8524590163934426\n",
      "Training f1 score :  [0.81516588 0.85714286]\n",
      "Testing f1 score :  [0.82352941 0.87323944]\n",
      "\n",
      "Result for Gaussian Naive Bayes Classification\n",
      "Training Accuracy :  0.8347107438016529\n",
      "Testing Accuracy :  0.8524590163934426\n",
      "Training f1 score :  [0.81481481 0.85074627]\n",
      "Testing f1 score :  [0.82352941 0.87323944]\n",
      "\n",
      "Result for Decision Tree Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.7868852459016393\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.77192982 0.8       ]\n",
      "\n",
      "Result for Random Forest Classification\n",
      "Training Accuracy :  1.0\n",
      "Testing Accuracy :  0.8852459016393442\n",
      "Training f1 score :  [1. 1.]\n",
      "Testing f1 score :  [0.87272727 0.89552239]\n",
      "\n",
      "Result for K-Nearest Neighbours Classification\n",
      "Training Accuracy :  0.78099173553719\n",
      "Testing Accuracy :  0.639344262295082\n",
      "Training f1 score :  [0.76444444 0.7953668 ]\n",
      "Testing f1 score :  [0.60714286 0.66666667]\n",
      "\n",
      "Result for AdaBoost Classification\n",
      "Training Accuracy :  0.9214876033057852\n",
      "Testing Accuracy :  0.9016393442622951\n",
      "Training f1 score :  [0.91324201 0.92830189]\n",
      "Testing f1 score :  [0.89285714 0.90909091]\n",
      "\n",
      "Result for Neural Network Classification\n",
      "Training Accuracy :  0.859504132231405\n",
      "Testing Accuracy :  0.8032786885245902\n",
      "Training f1 score :  [0.84259259 0.87313433]\n",
      "Testing f1 score :  [0.78571429 0.81818182]\n",
      "\n",
      "Result for SVM Classification\n",
      "Training Accuracy :  0.6652892561983471\n",
      "Testing Accuracy :  0.6885245901639344\n",
      "Training f1 score :  [0.56216216 0.72909699]\n",
      "Testing f1 score :  [0.57777778 0.75324675]\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Novelty1. Heart Disease Classification')\n",
    "heart_data = pd.read_csv(\"CP_Data/heart.csv\", sep=\",\")\n",
    "X_train, X_test, y_train, y_test = getTrainTestData(heart_data)\n",
    "classification(X_train, X_test, y_train, y_test,'14',hs = False)\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKertw96k9rb"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BMqpAiGk9rb"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## For Best Models\n",
    "Use the code cell below\n",
    "\n",
    "1. Find Dataset & Parameters from the Configs file (Be Careful with parity value, parity = Dataset number you're testing)\n",
    "2. Give the Dataset and Parameters for the Model\n",
    "3. Run and Enjoy the best result\n",
    "\n",
    "Add the proper RP_#_ according to your requirements in parameters. Example CP_3_X_train, CP_3_X_test, ...\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Diabetic Retinopathy -> CP_1\n",
    "2. Default of credit card clients -> CP_2\n",
    "3. Breast Cancer Wisconsin -> CP_3\n",
    "4. Statlog (Australian credit approval) -> CP_4\n",
    "5. Statlog (German credit data) -> CP_5\n",
    "6. Steel Plates Faults -> CP_6\n",
    "7. Adult -> CP_7\n",
    "8. Yeast -> CP_8\n",
    "9. Thoracic Surgery Data -> CP_9\n",
    "10. Seismic-Bumps -> CP_10\n",
    "\n",
    "**Model Mapper**\n",
    "1. Logistic Regression Classifier -> LRC()\n",
    "2. Naive Bayes Classifier -> NBC()\n",
    "3. Decision Tree Classifier -> DTC()\n",
    "4. Random Forest Classifier -> RFC()\n",
    "5. K-Nearest Neighbors -> KNN()\n",
    "6. AdaBoost Classifier -> ABC()\n",
    "7. Neural Network Classifier -> NNC()\n",
    "8. Support Vector Machine Classifier -> SVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRC(CP_10_X_train, CP_10_X_test, CP_10_y_train, CP_10_y_test, parity=10, hs=False, C=0.01, solver='sag')\n",
    "# NBC(X_train, X_test, y_train, y_test, parity=1, hs=False,)\n",
    "# DTC(X_train, X_test, y_train, y_test, parity=1, hs=False, max_depth=10, max_features='sqrt',min_samples_leaf=1,min_samples_split=2)\n",
    "# RFC(X_train, X_test, y_train, y_test, parity=1, hs=False, max_depth=10, max_features='sqrt',min_samples_leaf=1,min_samples_split=2, bootstrap=False,n_estimators=100)\n",
    "# KNN(X_train, X_test, y_train, y_test, parity=1, hs=False, n_neighbors=3, weights='uniform', p=1, algorithm='auto')\n",
    "# ABC(X_train, X_test, y_train, y_test, parity=1, hs=False, n_estimators=50, learning_rate=1)\n",
    "# NNC(X_train, X_test, y_train, y_test, parity=1, hs=False, activation='tangh', solver='adam', learning_rate='adaptive', momentum=0.6)\n",
    "# SVM(X_train, X_test, y_train, y_test, parity=1, hs=False, C=1, gamma='scale')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ClassificationNEW.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
