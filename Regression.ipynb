{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfG62S6xUQe0"
   },
   "source": [
    "## Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHla1Et7UQe3"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Importing Required Libraries\n",
    "\n",
    "The code block below will import all the libraries and dependencies for regression problems.\n",
    "\n",
    "**Run the code cell below** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yijqBNe7UQe5"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.svm               # For SVC\n",
    "import sklearn.metrics           # For accuracy_score\n",
    "import sklearn.model_selection   # For GridSearchCV and RandomizedSearchCV\n",
    "import scipy\n",
    "import scipy.stats               # For reciprocal distribution\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)       # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCzEMGNUUQfY"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Loading All Datasets\n",
    "\n",
    "The code block below will load all the datasets for regression problems.\n",
    "\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Wine Quality -> RP_1\n",
    "2. Communities and Crime -> RP_2\n",
    "3. QSAR aquatic toxicity -> RP_3\n",
    "4. Parkinson Speech -> RP_4\n",
    "5. Facebook metrics -> RP_5\n",
    "6. Bike Sharing (use hour data) -> RP_6\n",
    "7. Student Performance (use just student-por.csv if you do not know how to merge the math grades) -> RP_7\n",
    "8. Concrete Compressive Strength -> RP_8\n",
    "9. SGEMM GPU kernel performance -> RP_9\n",
    "10. Merck Molecular Activity Challenge (from Kaggle) -> RP_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtIAO_DFUQfZ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "M1Tr=[]\n",
    "M1Te=[]\n",
    "M2Tr=[]\n",
    "M2Te=[]\n",
    "MList=['SVM with RBF Kernel','SVM with Linear Kernel','Decision Tree Regressor','Random Forest Regressor','AdaBoost Regressor','Gaussian Process Regressor','Linear Regressor','Ridge Regressor']\n",
    "\n",
    "\"\"\"\n",
    "Splits the data into Features (X) and Labels (y)\n",
    "\"\"\"\n",
    "def splitData(data):\n",
    "    X = data.iloc[:,0:len(data.columns)-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "\"\"\"\n",
    "Splits data into Training Set and Testing Set. \n",
    "Size Ratio of Train:Test is 70:30 \n",
    "\"\"\"\n",
    "def getTrainTestData(data):\n",
    "    X,y = splitData(data)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.3,random_state=23)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Converts categorical features by encoding\n",
    "\"\"\"\n",
    "def convertCategorical(df):\n",
    "    categorical_feature_mask = df.dtypes==object\n",
    "    categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "    le = LabelEncoder()\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "    return df;\n",
    "\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x0tS2M4pUQfe",
    "outputId": "6c31eaa3-005e-47c8-c683-f0c622b174ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Wine Quality Data | 11 Features | 6497 Samples\n",
    "RP_1_red = pd.read_csv(\"RP_Data/winequality-red.csv\", sep=\";\",header=None,skiprows=1)\n",
    "RP_1_white = pd.read_csv(\"RP_Data/winequality-white.csv\", sep=\";\",header=None,skiprows=1)\n",
    "RP_1 = pd.concat([RP_1_red,RP_1_white])\n",
    "# print(RP_1.apply(minMax))\n",
    "RP_1_X_train, RP_1_X_test, RP_1_y_train, RP_1_y_test = getTrainTestData(RP_1)\n",
    "scaler = StandardScaler().fit(RP_1_X_train)\n",
    "RP_1_X_train = scaler.transform(RP_1_X_train)\n",
    "RP_1_X_test = scaler.transform(RP_1_X_test)\n",
    "\n",
    "# Communities and Crime Data| 127 Features | 1994 Samples \n",
    "RP_2 = pd.read_csv('RP_Data/communities.data',header=None)\n",
    "RP_2 = RP_2.drop([0, 1, 2, 3, 4], axis=1) # removed first 5 columns. non predictive\n",
    "RP_2 = RP_2.replace('?',0)\n",
    "# print(RP_2.apply(minMax))\n",
    "RP_2_X_train, RP_2_X_test, RP_2_y_train, RP_2_y_test = getTrainTestData(RP_2)\n",
    "\n",
    "\n",
    "# QSAR Aquatic Toxicity Data | 8 Features | 546 Samples\n",
    "RP_3 = pd.read_csv(\"RP_Data/qsar_aquatic_toxicity.csv\", sep=\";\",header=None)\n",
    "# print(RP_3.apply(minMax))\n",
    "RP_3_X_train, RP_3_X_test, RP_3_y_train, RP_3_y_test = getTrainTestData(RP_3)\n",
    "scaler = StandardScaler().fit(RP_3_X_train)\n",
    "RP_3_X_train = scaler.transform(RP_3_X_train)\n",
    "RP_3_X_test = scaler.transform(RP_3_X_test)\n",
    "\n",
    "\n",
    "# Parkinson Speech Data | 14 Features | 690 Samples\n",
    "RP_4 = pd.read_csv(\"RP_Data/parkinsons_train_data.txt\", sep=\",\",header=None)\n",
    "RP_4 = RP_4.drop([28], axis=1) # removed last column. categorical output\n",
    "# print(RP_4_train.shape)\n",
    "# print(RP_4_test.shape)\n",
    "# print(RP_4_train[28].nunique())\n",
    "# print(RP_4_test[27].nunique())\n",
    "RP_4_X_train, RP_4_X_test, RP_4_y_train, RP_4_y_test = getTrainTestData(RP_4)\n",
    "scaler = StandardScaler().fit(RP_4_X_train)\n",
    "RP_4_X_train = scaler.transform(RP_4_X_train)\n",
    "RP_4_X_test = scaler.transform(RP_4_X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Facebook Data | 18 Features | 500 Samples \n",
    "RP_5 = pd.read_csv(\"RP_Data/dataset_Facebook.csv\", sep=\";\")\n",
    "RP_5 = convertCategorical(RP_5)\n",
    "RP_5  = RP_5.fillna(RP_5.mean())\n",
    "# print(RP_5.apply(minMax))\n",
    "RP_5_X_train, RP_5_X_test, RP_5_y_train, RP_5_y_test = getTrainTestData(RP_5)\n",
    "scaler = StandardScaler().fit(RP_5_X_train)\n",
    "RP_5_X_train = scaler.transform(RP_5_X_train)\n",
    "RP_5_X_test = scaler.transform(RP_5_X_test)\n",
    "\n",
    "\n",
    "# Bike Sharing Hours Data | 16 Features | 17379 Samples \n",
    "RP_6 = pd.read_csv(\"RP_Data/hour.csv\", sep=\",\")\n",
    "RP_6 = RP_6.drop(['instant'], axis=1) # removed second last column. non predictive\n",
    "RP_6 = convertCategorical(RP_6)\n",
    "# print(RP_6.apply(minMax))\n",
    "RP_6_X_train, RP_6_X_test, RP_6_y_train, RP_6_y_test = getTrainTestData(RP_6)\n",
    "scaler = StandardScaler().fit(RP_6_X_train)\n",
    "RP_6_X_train = scaler.transform(RP_6_X_train)\n",
    "RP_6_X_test = scaler.transform(RP_6_X_test)\n",
    "\n",
    "\n",
    "# Student Performance Data | 32 Features | 4934964982 Samples\n",
    "RP_7 = pd.read_csv(\"RP_Data/student-por.csv\", sep=\";\")\n",
    "RP_7 = convertCategorical(RP_7)\n",
    "# print(RP_7.apply(minMax))\n",
    "RP_7_X_train, RP_7_X_test, RP_7_y_train, RP_7_y_test = getTrainTestData(RP_7)\n",
    "\n",
    "\n",
    "# Concrete Data | 8 Features | 1030 Samples\n",
    "RP_8 =  pd.read_excel (r'RP_Data/Concrete_Data.xls',skiprows=1,header=None)\n",
    "# print(RP_8.apply(minMax))\n",
    "RP_8_X_train, RP_8_X_test, RP_8_y_train, RP_8_y_test = getTrainTestData(RP_8)\n",
    "scaler = StandardScaler().fit(RP_8_X_train)\n",
    "RP_8_X_train = scaler.transform(RP_8_X_train)\n",
    "RP_8_X_test = scaler.transform(RP_8_X_test)\n",
    "\n",
    "\n",
    "# SGEMM GPU kernel performance Data | 14 Features | 241600 Samples \n",
    "RP_9 = pd.read_csv(\"RP_Data/sgemm_product.csv\", sep=\",\")\n",
    "RP_9['Run (ms)'] = RP_9.iloc[:, -4:].sum(axis=1)/4 #add column of average run of 4 runs\n",
    "RP_9 = RP_9.drop(['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'], axis = 1)  #drop 4 runs column\n",
    "# print(RP_9.apply(minMax))\n",
    "RP_9_X_train, RP_9_X_test, RP_9_y_train, RP_9_y_test = getTrainTestData(RP_9)\n",
    "scaler = StandardScaler().fit(RP_9_X_train)\n",
    "RP_9_X_train = scaler.transform(RP_9_X_train)\n",
    "RP_9_X_test = scaler.transform(RP_9_X_test)\n",
    "\n",
    "\n",
    "#Merck Molecular Dataset 1 | 5877 Features | 8716 Samples \n",
    "npzfile = np.load('RP_Data/File1.npz')\n",
    "RP_101_X = npzfile['arr_0']\n",
    "RP_101_y = npzfile['arr_1']\n",
    "RP_101_X_train, RP_101_X_test, RP_101_y_train, RP_101_y_test = sklearn.model_selection.train_test_split(RP_101_X,RP_101_y,test_size=0.3,random_state=23)\n",
    "\n",
    "\n",
    "#Merck Molecular Dataset 2 | 4306 Features | w Samples \n",
    "npzfile = np.load('RP_Data/File2.npz')\n",
    "RP_102_X = npzfile['arr_0']\n",
    "RP_102_y = npzfile['arr_1']\n",
    "RP_102_X_train, RP_102_X_test, RP_102_y_train, RP_102_y_test = sklearn.model_selection.train_test_split(RP_102_X,RP_102_y,test_size=0.3,random_state=23)\n",
    "\n",
    "print('Regression Data Loaded Successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgHN-2vOUQfl"
   },
   "outputs": [],
   "source": [
    "# # Merck Molecular Activity Challenge | RAW FILE LOADING AND CACHING PROCESS | Given By The Professor\n",
    "# with open(\"ACT2_competition_training.csv\") as f:\n",
    "#     cols = f.readline().rstrip('\\n').split(',') # Read the header line and get list of column names\n",
    "\n",
    "# # Load the actual data, ignoring first column and using second column as targets.\n",
    "# RP_101_X = np.loadtxt(\"ACT2_competition_training.csv\", delimiter=',', usecols=range(2, len(cols)), skiprows=1, dtype=np.uint8)\n",
    "# RP_101_y = np.loadtxt(\"ACT2_competition_training.csv\", delimiter=',', usecols=[1], skiprows=1)\n",
    "# np.savez('File1',RP_101_X,RP_101_y)\n",
    "\n",
    "# with open(\"ACT4_competition_training.csv\") as f:\n",
    "#     cols = f.readline().rstrip('\\n').split(',') # Read the header line and get list of column names\n",
    "\n",
    "# # Load the actual data, ignoring first column and using second column as targets.\n",
    "# RP_102_X = np.loadtxt(\"ACT4_competition_training.csv\", delimiter=',', usecols=range(2, len(cols)), skiprows=1, dtype=np.uint8)\n",
    "# RP_102_y = np.loadtxt(\"ACT4_competition_training.csv\", delimiter=',', usecols=[1], skiprows=1)\n",
    "# np.savez('File2',RP_102_X,RP_102_y)\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 3. Regressors and Hyper Parameter Search Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## Hyper Parameter Search Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucJTYa17UQfq"
   },
   "outputs": [],
   "source": [
    "def gridSearchSVR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma' : [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "\n",
    "def randomSearchSVR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'C'     : scipy.stats.reciprocal(1.0, 1000.),\n",
    "        'gamma' : scipy.stats.reciprocal(0.01, 10.),\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwUYUfXRUQft"
   },
   "outputs": [],
   "source": [
    "def gridSearchDTR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "    \n",
    "def randomSearchDTR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_grid,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T09P4FEiUQfv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def gridSearchRFR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10,20,50,100,150,200,250]\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "    \n",
    "\n",
    "def randomSearchRFR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_grid = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'n_estimators': [10,20,50,100,150,200,250]\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_grid,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kY6J5WvcUQf0"
   },
   "outputs": [],
   "source": [
    "def gridSearchABR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'n_estimators': [10,20,50,100,150,200,500],\n",
    "        'learning_rate': [0.001,0.01,0.05,0.1,0.2,0.5,0.6,0.9,1,1.2,1.5,2],\n",
    "        'loss' : ['linear', 'square', 'exponential']\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "    \n",
    "def randomSearchABR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'n_estimators': scipy.stats.randint(10,500),\n",
    "        'learning_rate': scipy.stats.reciprocal(0.001, 1.5),\n",
    "         'loss' : ['linear', 'square', 'exponential']\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Process Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivpqJkq9UQf5"
   },
   "outputs": [],
   "source": [
    "def gridSearchGPR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        \"alpha\": np.logspace(-5, 5, 50)\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "    \n",
    "def randomSearchGPR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        \"alpha\": np.logspace(-5, 5, 50)\n",
    "    }\n",
    "    random_search = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regressor Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rROmuyH7Vpv"
   },
   "outputs": [],
   "source": [
    "def gridSearchRIR(model,X_train,y_train):\n",
    "    print('Grid Search')\n",
    "    param_grid = {\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],\n",
    "        'alpha': np.logspace(-5, 5, 50),\n",
    "        'normalize' : [True, False]\n",
    "    }\n",
    "    gridcv = GridSearchCV(model, param_grid, cv=5).fit(X_train,y_train)\n",
    "    print(gridcv.best_params_)\n",
    "    return gridcv.best_estimator_\n",
    "    \n",
    "def randomSearchRIR(model,X_train,y_train):\n",
    "    print('Randomized Search')\n",
    "    param_distributions = {\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],\n",
    "        'alpha': scipy.stats.reciprocal(0.00001, 100.),\n",
    "        'normalize' : [True, False]\n",
    "    \n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(model, param_distributions,cv=5, n_iter=30, random_state=23).fit(X_train,y_train)\n",
    "    print(randcv.best_params_)\n",
    "    return randcv.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreHelper(rgr, X_train, X_test, y_train, y_test, parity):\n",
    "    if parity == 1:\n",
    "        print('Pearson Corelation Calculated and Added')\n",
    "        M1Tr.append(pearsonr(y_train,rgr.predict(X_train))[0]**2)\n",
    "        M1Te.apppend(pearsonr(y_test,rgr.predict(X_test))[0]**2)\n",
    "    elif parity == 2:\n",
    "        print('Pearson Corelation Calculated and Added')\n",
    "        M2Tr.append(pearsonr(y_train,rgr.predict(X_train))[0]**2)\n",
    "        M2Te.apppend(pearsonr(y_test,rgr.predict(X_test))[0]**2)\n",
    "    elif parity == 3:\n",
    "        print('Training Mean Squared Error ',mean_squared_error(y_train,rgr.predict(X_train)))\n",
    "        print('Testing Mean Squared Error ',mean_squared_error(y_test,rgr.predict(X_test)))\n",
    "    else:\n",
    "        print('Training R2 Score ',rgr.score(X_train, y_train))\n",
    "        print('Testing R2 Score ',rgr.score(X_test, y_test))\n",
    "        \n",
    "def merckScore(x,y):\n",
    "    for i in x:\n",
    "        print('Evaluation Using ',MList[i],' : ')\n",
    "        print(*(x[i]+y[i])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "## Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regressor with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws6YtFqyUQf_"
   },
   "outputs": [],
   "source": [
    "def rbfSVR(X_train, X_test, y_train, y_test, hs, parity, C=1, gamma='scale'):\n",
    "    print('\\nResult for RBF Support Vector Regression')\n",
    "    rgr = SVR(C=C, gamma=gamma)\n",
    "    if hs:\n",
    "        rgr = gridSearchSVR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchSVR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regressor with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTrqHVmhUQgF"
   },
   "outputs": [],
   "source": [
    "def linearSVR(X_train, X_test, y_train, y_test, hs, parity, C=1, gamma='scale'):\n",
    "    print('\\nResult for Linear Support Vector Regression')\n",
    "    rgr = SVR(kernel='linear', C=C, gamma=gamma)\n",
    "    if hs:\n",
    "        rgr = gridSearchSVR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchSVR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0jcHyc2UQgM"
   },
   "outputs": [],
   "source": [
    "def DTR(X_train, X_test, y_train, y_test, hs, parity,max_depth=None, max_features=None,min_samples_leaf=1,min_samples_split=2):\n",
    "    print('\\nResult for Decision Tree Regression')\n",
    "    rgr = DecisionTreeRegressor(max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split, random_state=23)       \n",
    "    if hs:\n",
    "        rgr = gridSearchDTR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchDTR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jFTkhW11UQgQ"
   },
   "outputs": [],
   "source": [
    "def RFR(X_train, X_test, y_train, y_test, hs, parity, max_depth=None, max_features='auto',min_samples_leaf=1,min_samples_split=2, bootstrap=True,n_estimators=100):\n",
    "    print('\\nResult for Random Forest Regression')\n",
    "    rgr = RandomForestRegressor(max_depth=max_depth, max_features=max_features,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split, bootstrap=bootstrap, n_estimators=n_estimators, random_state=23)\n",
    "    if hs:\n",
    "        rgr = gridSearchRFR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchRFR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2Yv1PfPUQgV"
   },
   "outputs": [],
   "source": [
    "def ABR(X_train, X_test, y_train, y_test, hs, parity,n_estimators=50, learning_rate=1, loss='linear'):\n",
    "    print('\\nResult for AdaBoost Regression')\n",
    "    rgr = AdaBoostRegressor(random_state=23,n_estimators=n_estimators, learning_rate=learning_rate, loss=loss)\n",
    "    if hs:\n",
    "        rgr = gridSearchABR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchABR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gsS7RhFUQga"
   },
   "outputs": [],
   "source": [
    "def GPR(X_train, X_test, y_train, y_test, hs, parity, alpha=1e-10):\n",
    "    print('\\nResult for Gaussian Process Regression')\n",
    "    rgr = GaussianProcessRegressor(alpha=alpha)\n",
    "    if hs:\n",
    "        rgr = gridSearchGPR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchGPR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = GaussianProcessRegressor().fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0r1zGUysUQgd"
   },
   "outputs": [],
   "source": [
    "def LIR(X_train, X_test, y_train, y_test, hs, parity):\n",
    "    print('\\nResult for Linear Regression')\n",
    "    rgr = LinearRegression().fit(X_train, y_train)\n",
    "    scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RIR(X_train, X_test, y_train, y_test, hs, parity, solver='auto',alpha=1,normalize=False):\n",
    "    print('\\nResult for Ridge Regression')\n",
    "    rgr = Ridge(solver=solver,alpha=alpha,normalize=normalize)\n",
    "    if hs:\n",
    "        rgr = gridSearchRIR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "        rgr = randomSearchRIR(rgr,X_train,y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)\n",
    "    else:\n",
    "        rgr = rgr.fit(X_train, y_train)\n",
    "        scoreHelper(rgr, X_train, X_test, y_train, y_test, parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 4. Working with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI4JHBxUUQgf"
   },
   "outputs": [],
   "source": [
    "def regress(X_train, X_test, y_train, y_test,hs=False, parity=0):\n",
    "    rbfSVR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    linearSVR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    DTR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    RFR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    ABR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    GPR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    LIR(X_train, X_test, y_train, y_test, hs, parity)\n",
    "    RIR(X_train, X_test, y_train, y_test, hs, parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ghgp4bbIUQgi",
    "outputId": "7fcadf7b-9168-43a9-ae87-08454ecc76b2"
   },
   "outputs": [],
   "source": [
    "print('Wine Quality Dataset')\n",
    "regress(RP_1_X_train, RP_1_X_test, RP_1_y_train, RP_1_y_test, hs = False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nCommunities and Crimes Dataset ')\n",
    "regress(RP_2_X_train, RP_2_X_test, RP_2_y_train, RP_2_y_test, hs = False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nQSAR Aquatic Toxicity Dataset Training')\n",
    "regress(RP_3_X_train, RP_3_X_test, RP_3_y_train, RP_3_y_test, hs = False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nParkinsons Dataset')\n",
    "regress(RP_4_X_train, RP_4_X_test, RP_4_y_train, RP_4_y_test, hs = False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nFacebook Metrics Dataset')\n",
    "regress(RP_5_X_train, RP_5_X_test, RP_5_y_train, RP_5_y_test, hs=False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nBike Sharing Dataset')\n",
    "regress(RP_6_X_train, RP_6_X_test, RP_6_y_train, RP_6_y_test, hs=False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nStudent Performance Dataset')\n",
    "regress(RP_7_X_train, RP_7_X_test, RP_7_y_train, RP_7_y_test, hs=False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nConcrete Compressive Dataset')\n",
    "regress(RP_8_X_train, RP_8_X_test, RP_8_y_train, RP_8_y_test, hs=False, parity=0)\n",
    "print('-------------------------------------------------------')\n",
    "print('\\n\\nSGEMM GPU Performance Dataset')\n",
    "print('Might Crash in Gaussian Process Regression due to lack of memory.')\n",
    "regress(RP_9_X_train, RP_9_X_test, RP_9_y_train, RP_9_y_test, hs=False, parity=0)\n",
    "print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initiating Merck Sequence. Please Be Patient.')\n",
    "print('Merck Results can be found in RP_Data/Hyperparameter Search Results/RP_10 Merck Result')\n",
    "print('Merck Molecular Dataset 1')\n",
    "regress(RP_101_X_train, RP_101_X_test, RP_101_y_train, RP_101_y_test, parity=1)\n",
    "print('-------------------------------------------------------')\n",
    "print('Merck Molecular Dataset 2')\n",
    "regress(RP_102_X_train, RP_102_X_test, RP_102_y_train, RP_102_y_test, parity=2)\n",
    "print('Training Complete')\n",
    "print('Merck Score Training')\n",
    "merckScore(M1Tr,M2Tr)\n",
    "print('Merck Score Testing')\n",
    "merckScore(M1Te,M2Te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "\n",
    "## For Best Models\n",
    "\n",
    "Use the code cell below:\n",
    "\n",
    "1. Find Dataset & Parameters from the Configs file\n",
    "2. Give the Dataset and Parameters for the Model\n",
    "3. Run and Enjoy the best result\n",
    "\n",
    "Add the proper RP_#_ according to your requirements in parameters. Example RP_3_X_train, RP_3_X_test, ...\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Wine Quality -> RP_1\n",
    "2. Communities and Crime -> RP_2\n",
    "3. QSAR aquatic toxicity -> RP_3\n",
    "4. Parkinson Speech -> RP_4\n",
    "5. Facebook metrics -> RP_5\n",
    "6. Bike Sharing (use hour data) -> RP_6\n",
    "7. Student Performance (use just student-por.csv if you do not know how to merge the math grades) -> RP_7\n",
    "8. Concrete Compressive Strength -> RP_8\n",
    "9. SGEMM GPU kernel performance -> RP_9\n",
    "10. Merck Molecular Activity Challenge (from Kaggle) -> RP_10\n",
    "\n",
    "**Model Mapper**\n",
    "1. Support Vector Regressor with RBF kernel -> rbfSVR()\n",
    "1. Support Vector Regressor with Linear kernel -> linearSVR()\n",
    "3. Decision Tree Regressor -> DTR()\n",
    "4. Random Forest Regressor -> RFR()\n",
    "5. AdaBoost Regressor -> ABR()\n",
    "6. Gaussian Process Regressor -> GPR()\n",
    "7. Linear Regressor -> LIR()\n",
    "8. Ridge Regressor -> RIR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbfSVR(X_train, X_test, y_train, y_test, hs=False, parity=0, C=0.1, gamma=1)\n",
    "# linearSVR(X_train, X_test, y_train, y_test, hs=False, parity=0, C=0.1, gamma =1)\n",
    "# DTR(X_train, X_test, y_train, y_test, hs=False, parity=0, max_depth=10, max_features='sqrt',min_samples_leaf=1,min_samples_split=2)\n",
    "# RFR(X_train, X_test, y_train, y_test, hs=False, parity=0, max_depth=10, max_features='sqrt',min_samples_leaf=1,min_samples_split=2, bootstrap=False,n_estimators=100)\n",
    "# ABR(RP_1_X_train, RP_1_X_test, RP_1_y_train, RP_1_y_test, hs=False, parity=0, n_estimators=150, learning_rate=0.1, loss='exponential')\n",
    "# GPR(X_train, X_test, y_train, y_test, hs=False, parity=0, alpha=1e-10)\n",
    "# LIR(X_train, X_test, y_train, y_test, hs=False, parity=0)\n",
    "# RIR(X_train, X_test, y_train, y_test, hs=False, parity=0, solver='svd',alpha=0.5,normalize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
